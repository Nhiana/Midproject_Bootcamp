{
 "cells": [
  {
   "cell_type": "raw",
   "id": "22dbba77-4067-47fe-b373-d006ac055b25",
   "metadata": {},
   "source": [
    "Analyzing Factors Contributing to Car Crashes: A Comprehensive Study\n",
    "\n",
    "Understanding Car Crash Dynamic: \n",
    "- Patterns\n",
    "- Causes\n",
    "- Trends\n",
    "\n",
    "This project deals with car crash data. It analyzes the locations, weather conditions, and road conditions associated witcar crashes.h "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e9609d-36e8-476b-b0ff-23d1fbd94d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01828c5-3afe-4621-8671-b68a53f3a7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv('..\\data\\Crash_Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd18e059-b0c4-4b13-a037-5570a14993af",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a06420-5cb2-4209-98b8-74c8f958da7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile functions.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def column_rename (df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function renames column names by removing spaces and converting to lower case\n",
    "    Inputs: df of type pandas dataframe\n",
    "    Outputs: returns the dataframe with the renamed columns\n",
    "    \"\"\"\n",
    "    cols =[]\n",
    "    for x in df.columns:\n",
    "        if isinstance(x, str):\n",
    "            cols.append(x.lower().replace(' ', '_'))\n",
    "        else:\n",
    "            cols.append(x)\n",
    "            \n",
    "    df.columns=cols\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def col_replace_dash (df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function renames column names by removing spaces and converting to lower case\n",
    "    Inputs: df of type pandas dataframe\n",
    "    Outputs: returns the dataframe with the renamed columns\n",
    "    \"\"\"\n",
    "    cols =[]\n",
    "    for x in df.columns:\n",
    "        if isinstance(x, str):\n",
    "            cols.append(x.lower().replace('-', '_'))\n",
    "        else:\n",
    "            cols.append(x)\n",
    "            \n",
    "    df.columns=cols\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def clean_agency_name (df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function groups the same values of the agency name column\n",
    "    It uses a dictionary to replace the redundant values\n",
    "    Inputs: df type pandas dataframe\n",
    "    Outputs: returns the dataframe with the renamed columns\n",
    "    \"\"\"\n",
    "    new_row_values = {'montgomery county police': 'montgomery', 'rockville police departme' : 'rockville', 'gaithersburg police depar' : 'gaithersburg',\n",
    "    'takoma park police depart': 'takoma', 'maryland-national capital': 'maryland'}\n",
    "    df['agency_name']= df['agency_name'].replace(new_row_values)\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_collision_type(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function renames the clean collision type column\n",
    "    It uses combination of regex and a dictionary to do so\n",
    "    Inputs: df of type pandas dataframe\n",
    "    Outputs: returns the dataframe with the renamed values\n",
    "    \"\"\"\n",
    "    replace_short= {'\\\\bdir\\\\b' : 'direction', '\\\\brend\\\\b' : 'rear end'}\n",
    "    df['collision_type']= df['collision_type'].replace(replace_short, regex=True)\n",
    "    return df\n",
    "    \n",
    "    \n",
    "def df_to_lower (df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function converts all the values in all the columns to lower case\n",
    "    Inputs: df of type pandas dataframe\n",
    "    Outputs: returns the dataframe with the string values in lower case\n",
    "    \"\"\"\n",
    "    df = df.map(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "    return df\n",
    "\n",
    "\n",
    "def replace_invalids_of_column(df: pd.DataFrame, num_replacements: float, replacement_value:str, col_to_clean: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function removes the invalid values from the given column\n",
    "    Inputs: df of type pandas dataframe, the values that will replace the invalid values, and their frequencies\n",
    "    Outputs: returns dataframe with the replaced invalid values\n",
    "    \"\"\"\n",
    "    invalid_indices= df[df[col_to_clean] == 'invalid'].index\n",
    "    selected_indices = np.random.choice(invalid_indices, size=num_replacements, replace=False)\n",
    "    df.loc[selected_indices, col_to_clean] = replacement_value\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237f54fa-3f1a-4647-9627-94950fb0246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38fb4b5-6561-4c59-b600-8ce483b6960b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3990d892-15fd-482a-8efd-246ed9cae598",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= col_replace_dash(df)\n",
    "df= column_rename(df)\n",
    "df= df_to_lower(df)\n",
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d2ce0e-3111-420f-9edc-5bdbde05c3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd6af04-d908-417b-a931-0354bd1f63f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= clean_agency_name(df)\n",
    "df['agency_name'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8789c3b0-ff40-4a9f-b53d-6fd5a357ebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after checking the datatypes of the columns, we decided to cast the crash_date/time column to datetime datatype \n",
    "df['crash_date/time']=pd.to_datetime(df['crash_date/time'], format=\"%m/%d/%Y %I:%M:%S %p\")\n",
    "type(df['crash_date/time'])\n",
    "df['crash_date/time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ebebed-8a4a-4393-b233-c0752b265e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294c29b5-941e-42eb-8e79-e4aab78bb05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_null_percentages= df.isnull().sum()/len(df)*100\n",
    "display(original_null_percentages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4695efa6-ed29-46c1-afce-53345ec3f40b",
   "metadata": {},
   "source": [
    "After checking the percentage of missing values for the columns, we dropped the columns with a percentage greater than 20% and also those that were irrelevant to our analysis.\n",
    "We also made sure to keep the columns that were relevant to our business questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a11b604-df55-4053-8955-aaf1e63aea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop=['lane_type', 'off_road_description', 'municipality', 'related_non_motorist', 'non_motorist_substance_abuse',\n",
    "                 'first_harmful_event', 'second_harmful_event', 'fixed_oject_struck', 'junction', 'intersection_type', 'intersection_area', \n",
    "                 'route_type', 'mile_point_direction', 'lane_direction','direction', 'distance_unit' ,'road_name', 'cross_street_type', 'cross_street_name', \n",
    "                'surface_condition', 'traffic_control', 'driver_substance_abuse', 'road_alignment' , 'road_division', 'mile_point', 'distance']\n",
    "df.drop(columns_to_drop, axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e82819-6450-4f2f-b10d-92fcbf8ecd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rechecking the NaNs after dropping the columns with high percentage of missing values\n",
    "df.isnull().sum()/len(df)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed38288-c8d5-42d7-b25e-f7e5205d9170",
   "metadata": {},
   "source": [
    "After checking the percentage of NaNs for the remaining columns, the percentages for the following columns were insignificant\n",
    "We decided to drop the NaNs from these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b51bb41-7668-4271-9659-35ca5bbc790e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(subset=['hit/run', 'collision_type' , 'light'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a4a6fc-a682-4114-bd1b-52b52ee56984",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()/len(df)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343059fb-2410-4f9a-98d7-c097f0d8462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['light'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7bd247-8a0f-4010-8eeb-cb4458c0cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['collision_type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8230b91-654f-4c2a-b803-4d5374206231",
   "metadata": {},
   "source": [
    "After checking the value counts for the columns that are significant to our business questions, we decided to drop the NaN values from the road_condition and check its effect on the remaining columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438e7683-1d38-46e7-a575-f9e166aa0a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the value counts for road_condition\n",
    "display(df['road_condition'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf6e68c-d6b9-4fe5-be02-35e657ce8011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'unknown', 'other', and NaN values with 'invalid'\n",
    "df['road_condition'] = df['road_condition'].replace(['unknown', 'other', np.nan], 'invalid')\n",
    "\n",
    "# Calculate the sum of 'invalid' values\n",
    "sum_invalid_values = (df['road_condition'] == 'invalid').sum()\n",
    "\n",
    "# Displaying the current counts for the categories that are not invalid\n",
    "unique_values = df['road_condition'][~df['road_condition'].isin(['invalid', 'no defects'])].value_counts()\n",
    "\n",
    "# Calculate the total count of other values (excluding 'invalid' and 'no defects')\n",
    "other_values_count = df['road_condition'][~df['road_condition'].isin(['invalid', 'no defects'])].count()\n",
    "\n",
    "# Finding the amount of invalids to be replaced for each category\n",
    "distribution_amounts = (unique_values / other_values_count) * sum_invalid_values\n",
    "distribution_amounts= distribution_amounts.round(0)\n",
    "distribution_amounts['obstruction not signaled']+=1\n",
    "\n",
    "# Applying the function to clean the road_condition column and replace the invalid values\n",
    "for key, value in distribution_amounts.items():\n",
    "    replace_invalids_of_column(df, int(value), key, 'road_condition')\n",
    "\n",
    "display(df['road_condition'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ceb0ba-9459-4c06-abdf-10388a4a951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the value counts for road_grade\n",
    "df['road_grade'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1347b3-6e88-4e88-96dd-a736815aea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'unknown', 'other', and NaN values with 'invalid'\n",
    "df['road_grade'] = df['road_grade'].replace(['unknown', 'other', np.nan], 'invalid')\n",
    "\n",
    "# Calculate the sum of 'invalid' values\n",
    "sum_invalid_values = (df['road_grade'] == 'invalid').sum()\n",
    "\n",
    "# Displaying the current counts for the categories that are not invalid\n",
    "unique_values = df['road_grade'][~df['road_grade'].isin(['invalid'])].value_counts()\n",
    "\n",
    "# Calculate the total count of other values (excluding 'invalid')\n",
    "other_values_count = df['road_grade'][~df['road_grade'].isin(['invalid'])].count()\n",
    "\n",
    "# Finding the amount of invalids to be replaced for each category\n",
    "distribution_amounts = (unique_values / other_values_count) * sum_invalid_values\n",
    "distribution_amounts= distribution_amounts.round(0)\n",
    "\n",
    "# Applying the function to clean the road_grade column and replace the invalid values\n",
    "for key, value in distribution_amounts.items():\n",
    "    replace_invalids_of_column(df, int(value), key, 'road_grade')\n",
    "\n",
    "display(df['road_grade'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2333efe-7c77-4143-909e-716f284fb9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the value counts for light\n",
    "df['light'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d653af7-5bd9-424f-85f6-fafa423bc8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the value counts for weather\n",
    "df['weather'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374e5525-e2a4-49e3-8e0d-ef1b5fa22ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'unknown', 'other', and NaN values with 'invalid'\n",
    "df['weather'] = df['weather'].replace(['unknown', 'other', np.nan], 'invalid')\n",
    "\n",
    "# Calculate the sum of 'invalid' values\n",
    "sum_invalid_values = (df['weather'] == 'invalid').sum()\n",
    "\n",
    "# Displaying the current counts for the categories that are not invalid\n",
    "unique_values = df['weather'][~df['weather'].isin(['invalid'])].value_counts()\n",
    "\n",
    "# Calculate the total count of other values (excluding 'invalid')\n",
    "other_values_count = df['weather'][~df['weather'].isin(['invalid'])].count()\n",
    "\n",
    "# Finding the amount of invalids to be replaced for each category\n",
    "distribution_amounts = (unique_values / other_values_count) * sum_invalid_values\n",
    "distribution_amounts= distribution_amounts.round(0)\n",
    "distribution_amounts['clear']-=2\n",
    "\n",
    "# Applying the function to clean the weather column and replace the invalid values\n",
    "for key, value in distribution_amounts.items():\n",
    "    replace_invalids_of_column(df, int(value), key, 'weather')\n",
    "\n",
    "display(df['weather'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6644cd6-c2fe-43e2-a30f-516f8ff82b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= clean_collision_type(df)\n",
    "display(df['collision_type'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76ee685-f319-491a-9971-cdd5414027e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'unknown' and 'other' with 'invalid'\n",
    "df['collision_type'] = df['collision_type'].replace(['unknown', 'other'], 'invalid')\n",
    "\n",
    "# Calculate the sum of 'invalid' values\n",
    "sum_invalid_values = (df['collision_type'] == 'invalid').sum()\n",
    "\n",
    "# Displaying the current counts for the categories that are not invalid\n",
    "unique_values = df['collision_type'][~df['collision_type'].isin(['invalid'])].value_counts()\n",
    "\n",
    "# Calculate the total count of other values (excluding 'invalid')\n",
    "other_values_count = df['collision_type'][~df['collision_type'].isin(['invalid'])].count()\n",
    "\n",
    "\n",
    "# Finding the amount of invalids to be replaced for each category\n",
    "distribution_amounts = (unique_values / other_values_count) * sum_invalid_values\n",
    "distribution_amounts= distribution_amounts.round(0)\n",
    "\n",
    "distribution_amounts['same direction rear end']-=1\n",
    "\n",
    "# Applying the function to clean the collision_type column and replace the invalid values\n",
    "for key, value in distribution_amounts.items():\n",
    "    replace_invalids_of_column(df, int(value), key, 'collision_type')\n",
    "\n",
    "display(df['collision_type'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6a77f5-acf7-444f-a305-7a05cc500c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final check \n",
    "df.isnull().sum()/len(df)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5ee3bd-0eea-4b04-97bf-0c272d4ba786",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('..\\data\\clean_crash_data.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6af330-1a63-4191-8e06-8c6b50ed103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb73bca8-78c3-47e0-b953-70732fb30ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean= pd.read_csv('..\\data\\clean_crash_data.csv')\n",
    "display(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ef754b-d9c1-4b77-961f-c100583af844",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
